<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Number of Categories for K-Means: Elbow and Silhouette Methods | Stanislav Myachenkov</title>
<meta name="keywords" content="machine learning, categorization, k-means">
<meta name="description" content="K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number.
Sometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving.">
<meta name="author" content="">
<link rel="canonical" href="https://smyachenkov.com/number-of-categories-for-k-means/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.3613efbd0b1772781e8f49935e973cae632a7f61471c05b17be155505ccf87b5.css" integrity="sha256-NhPvvQsXcngej0mTXpc8rmMqf2FHHAWxe&#43;FVUFzPh7U=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js" integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG&#43;9vmJ0cTS&#43;ovo0FeA="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://smyachenkov.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://smyachenkov.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://smyachenkov.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://smyachenkov.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://smyachenkov.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-V263ZCTJXL"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-V263ZCTJXL', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="Number of Categories for K-Means: Elbow and Silhouette Methods" />
<meta property="og:description" content="K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number.
Sometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://smyachenkov.com/number-of-categories-for-k-means/" /><meta property="article:section" content="" />
<meta property="article:published_time" content="2019-05-26T00:00:00+03:00" />
<meta property="article:modified_time" content="2019-05-26T00:00:00+03:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Number of Categories for K-Means: Elbow and Silhouette Methods"/>
<meta name="twitter:description" content="K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number.
Sometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Number of Categories for K-Means: Elbow and Silhouette Methods",
      "item": "https://smyachenkov.com/number-of-categories-for-k-means/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Number of Categories for K-Means: Elbow and Silhouette Methods",
  "name": "Number of Categories for K-Means: Elbow and Silhouette Methods",
  "description": "K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number.\nSometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving.",
  "keywords": [
    "machine learning", "categorization", "k-means"
  ],
  "articleBody": "K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number.\nSometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving. For example, if you want to divide the dataset of people’s measurements into t-shirt sizes, you already know that t-shirts are measured from XXS to XXL and you can say with confidence that you know how many categories your data will have.\nBut often we face another type of a problem — when you don’t know the number of categories and you want to find it. One example of this problem is categorization of social media hashtags. In my previous post, you can read more about it.\nThere are a lot of methods of finding optimal number of categories in a dataset, and I will focus on the 2 most popular for the K-Means algorithm: the Elbow and the Silhouette methods.\nDataset I will test both methods on a small synthetic dataset of Instagram posts with 50 entries. It contains 50 entries with 8 groups of 5 posts from different categories plus 2 groups of 5 posts from mixed categories.\n{camping, mothernature, hike, earth, rain, wildlife, landscapestyles, naturewalk, natureonly} ... {streetview, streetphotographers, streetclassics, street_photo_club, streetphotographers} ... {architecture, archilovers, architecture_hunter, architecturelovers, creative_architecture} ... {ireland, dublin, guinness, instaireland, discoverireland} ... {ocean, sand, ocean, water, waves, seaside, wave} ... {portrait_shots, portrait_mood, portraitsociety, portraitvision, portraitoftheday, portraitmode} ... {ireland, dublin, guinness, instaireland, discoverireland, camping, mothernature, hike, earth, rain} ... {catsofinstagram, cat, cats, cats_of_instagram, catoftheday, petstagram, catsagram} ... {minimal_perfection, minimalmood, minimalistic, minimalismo, minimal, minimalism_world} ... {architecture, archilovers, creative_architecture, minimalmood, minimalistic, minimal} Lets try it!\nElbow method The general idea for both methods is to try different values for k number and measure some of its metrics. In the elbow method, it’s the sum of the squared distances of an object to the closest centroid.\nLet’s measure how different the performance params will be for the number of categories from 1 to 20.\nwith open(\"posts.txt\", encoding=\"utf-8\") as inp:  posts = inp.readlines() vectorizer = TfidfVectorizer(use_idf=True) posts_coordinates = vectorizer.fit_transform(posts) print(\"Number of clusters / Inertia / Diff\") previous = 0 for clusters_amount in range(1, 21, step):  model = KMeans(  n_clusters=clusters_amount,  init='k-means++',  max_iter=10,  n_init=5,  verbose=False  )  model.fit_predict(posts_coordinates)  inertia = model.inertia_  diff = previous - inertia  previous = inertia  print(\"%s: %s%s\" % (clusters_amount, inertia, \"-\" if clusters_amount == 1 else diff)) This script gives us the following data where Categories column is the number of categories, Inertia is the sum of squared distances to the closest centroid, and Diff is the difference between current and previous values of Inertia:\nCategories Inertia Diff 1 43,56 - 2 37,13 6,43 3 31,82 5,30 4 26,74 5,08 5 21,82 4,92 6 17,93 3,88 7 12,74 5,19 8 9,07 3,66 9 7,74 1,33 10 6,57 1,16 11 5,99 0,57 12 5,76 0,23 13 5,54 0,21 14 5,31 0,22 15 5,10 0,21 16 4,86 0,23 17 4,64 0,22 18 4,56 0,08 19 4,25 0,30 20 4,05 0,20 Here we can see that the Inertia parameter almost stops decreasing after the number of categories reaches 8. It’s even more clear on the second diagram, where the largest drop in speed has been achieved after the 8th category and every difference after that does not change much.\nNow let’s try to confirm this number with a silhouette method.\nSilhouette method Silhouette metric has its values in a range from -1 to 1 and measures how far or close are points in clusters to points of another cluster. The higher the value — the farther points of clusters are from each other. And that’s what we want to achieve — more distinct clusters that do not intersect.\nwith open(\"posts.txt\", encoding=\"utf-8\") as inp:  posts = inp.readlines() vectorizer = TfidfVectorizer(use_idf=True) posts_coordinates = vectorizer.fit_transform(posts) print(\"Number of clusters / Silhouette score\") for clusters_amount in range(2, 21, step):  model = KMeans(  n_clusters=clusters_amount,  init='k-means++',  max_iter=10,  n_init=5,  verbose=False  )  categories = model.fit_predict(posts_coordinates)  silhouette_avg = silhouette_score(posts_coordinates, categories)  print(\"%s: %s\" % (clusters_amount, silhouette_avg)) This script gives us the following data:\nCategories Silhouette score 2 0,13 3 0,23 4 0,29 5 0,35 6 0,41 7 0,48 8 0,51 9 0,50 10 0,48 11 0,47 12 0,45 13 0,43 14 0,41 15 0,39 16 0,39 17 0,37 18 0,39 19 0,34 20 0,34 The highest score is achieved in 8 categories, the same number as the one we got using the elbow method.\nConclusion Choosing the correct and optimal number of categories is a very frequent problem in unsupervised machine learning and data clustering. Sometimes you can make a fairly good assumption by just looking at your data and studying its domain. But if you want to adjust this number to be more precise or find order in chaotic data it’s good to test different metrics and see what insights about your data they provide. In this post, I have tried only two methods for one problem, but there are many more. Don’t be afraid to try something new!\nLinks Scripts and dataset from this post: https://github.com/smyachenkov/clustering_categories_number_demo\nElbow method description: https://wikipedia.org/wiki/Elbow_method_(clustering)\nSilhouette method description: https://wikipedia.org/wiki/Silhouette_(clustering))\nProblem of choosing number of clusters in a dataset: https://wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set\nK-Means implementation in scikit-learn library: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\nSilhouette metric implementation in scikit-learn library: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html\n",
  "wordCount" : "901",
  "inLanguage": "en",
  "datePublished": "2019-05-26T00:00:00+03:00",
  "dateModified": "2019-05-26T00:00:00+03:00",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://smyachenkov.com/number-of-categories-for-k-means/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Stanislav Myachenkov",
    "logo": {
      "@type": "ImageObject",
      "url": "https://smyachenkov.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://smyachenkov.com/" accesskey="h" title="Stanislav Myachenkov (Alt + H)">Stanislav Myachenkov</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://smyachenkov.com/posts" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://smyachenkov.com/this-is-singapore" title="Singapore">
                    <span>Singapore</span>
                </a>
            </li>
            <li>
                <a href="https://smyachenkov.com/tags" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://smyachenkov.com/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://smyachenkov.com/index.xml" title="RSS Feed">
                    <span>RSS Feed</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title">
      Number of Categories for K-Means: Elbow and Silhouette Methods
    </h1>
    <div class="post-meta"><span title='2019-05-26 00:00:00 +0300 +0300'>May 26, 2019</span>&nbsp;·&nbsp;5 min

</div>
  </header> 
  <div class="post-content"><p><a href="https://wikipedia.org/wiki/K-means_clustering"><strong>K-Means</strong></a> is a very common and powerful clusterization algorithm widely used in an <a href="https://wikipedia.org/wiki/Unsupervised_learning">unsupervised machine learning</a> tasks for dividing data into categories.
The only decision you have to make is the number of clusters you want your data to be divided into — <em>k</em> number.</p>
<p>Sometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving. For example, if you want to divide the dataset of people&rsquo;s measurements into t-shirt sizes, you already know that t-shirts are measured from XXS to XXL and you can say with confidence that you know how many categories your data will have.</p>
<p>But often we face another type of a problem — when you don&rsquo;t know the number of categories and you want to find it. One example of this problem is categorization of social media hashtags. <a href="http://smyachenkov.com/posts/categorizing-instagram-tags-with-k-means/">In my previous post</a>, you can read more about it.</p>
<p>There are a lot of methods of finding optimal number of categories in a dataset, and I will focus on the 2 most popular for the K-Means algorithm: the <a href="https://wikipedia.org/wiki/Elbow_method_(clustering)">Elbow</a> and the <a href="https://wikipedia.org/wiki/Silhouette_(clustering)">Silhouette</a> methods.</p>
<h2 id="dataset">Dataset<a hidden class="anchor" aria-hidden="true" href="#dataset">#</a></h2>
<p>I will test both methods on a small synthetic <a href="https://raw.githubusercontent.com/smyachenkov/clustering_categories_number_demo/master/posts.txt">dataset</a> of Instagram posts with 50 entries. It contains 50 entries with 8 groups of 5 posts from different categories plus 2 groups of 5 posts from mixed categories.</p>
<pre tabindex="0"><code>{camping, mothernature, hike, earth, rain, wildlife, landscapestyles, naturewalk, natureonly}
...
{streetview, streetphotographers, streetclassics, street_photo_club, streetphotographers}
...
{architecture, archilovers, architecture_hunter, architecturelovers, creative_architecture}
...
{ireland, dublin, guinness, instaireland, discoverireland}
...
{ocean, sand, ocean, water, waves, seaside, wave}
...
{portrait_shots, portrait_mood, portraitsociety, portraitvision, portraitoftheday, portraitmode}
...
{ireland, dublin, guinness, instaireland, discoverireland, camping, mothernature, hike, earth, rain}
...
{catsofinstagram, cat, cats, cats_of_instagram, catoftheday, petstagram, catsagram}
...
{minimal_perfection, minimalmood, minimalistic, minimalismo, minimal, minimalism_world}
...
{architecture, archilovers, creative_architecture, minimalmood, minimalistic, minimal}
</code></pre><p>Lets try it!</p>
<h2 id="elbow-method">Elbow method<a hidden class="anchor" aria-hidden="true" href="#elbow-method">#</a></h2>
<p>The general idea for both methods is to try different values for <em>k</em> number and measure some of its metrics. In the elbow method, it&rsquo;s the sum of the squared distances of an object to the closest centroid.</p>
<p>Let&rsquo;s measure how different the performance params will be for the number of categories from 1 to 20.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;posts.txt&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> inp:
</span></span><span style="display:flex;"><span>    posts <span style="color:#f92672">=</span> inp<span style="color:#f92672">.</span>readlines()
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> TfidfVectorizer(use_idf<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>posts_coordinates <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(posts)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Number of clusters / Inertia / Diff&#34;</span>)
</span></span><span style="display:flex;"><span>previous <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> clusters_amount <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">21</span>, step):
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> KMeans(
</span></span><span style="display:flex;"><span>        n_clusters<span style="color:#f92672">=</span>clusters_amount,
</span></span><span style="display:flex;"><span>        init<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k-means++&#39;</span>,
</span></span><span style="display:flex;"><span>        max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>        n_init<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>        verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    model<span style="color:#f92672">.</span>fit_predict(posts_coordinates)
</span></span><span style="display:flex;"><span>    inertia <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>inertia_
</span></span><span style="display:flex;"><span>    diff <span style="color:#f92672">=</span> previous <span style="color:#f92672">-</span> inertia
</span></span><span style="display:flex;"><span>    previous <span style="color:#f92672">=</span> inertia
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (clusters_amount, inertia, <span style="color:#e6db74">&#34;-&#34;</span> <span style="color:#66d9ef">if</span> clusters_amount <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">else</span> diff))
</span></span></code></pre></div><p>This script gives us the following data where <strong>Categories</strong> column is the number of categories, <strong>Inertia</strong> is the sum of squared distances to the closest centroid, and <strong>Diff</strong> is the difference between current and previous values of Inertia:</p>
<pre tabindex="0"><code>Categories  Inertia Diff
1           43,56   -
2           37,13   6,43
3           31,82   5,30
4           26,74   5,08
5           21,82   4,92
6           17,93   3,88
7           12,74   5,19
8           9,07    3,66
9           7,74    1,33
10          6,57    1,16
11          5,99    0,57
12          5,76    0,23
13          5,54    0,21
14          5,31    0,22
15          5,10    0,21
16          4,86    0,23
17          4,64    0,22
18          4,56    0,08
19          4,25    0,30
20          4,05    0,20
</code></pre><p><img loading="lazy" src="/images/2_number-of-categories-for-k-means/elbow_chart.png" alt="Elbow chart"  />

<img loading="lazy" src="/images/2_number-of-categories-for-k-means/elbow_diff_chart.png" alt="Elbow diff chart"  />
</p>
<p>Here we can see that the Inertia parameter almost stops decreasing after the number of categories reaches <strong>8</strong>. It&rsquo;s even more clear on the second diagram, where the largest drop in speed has been achieved after the <strong>8</strong>th category and every difference after that does not change much.</p>
<p>Now let&rsquo;s try to confirm this number with a silhouette method.</p>
<h2 id="silhouette-method">Silhouette method<a hidden class="anchor" aria-hidden="true" href="#silhouette-method">#</a></h2>
<p>Silhouette metric has its values in a range from -1 to 1 and measures how far or close are points in clusters to points of another cluster. The higher the value — the farther points of clusters are from each other. And that&rsquo;s what we want to achieve — more distinct clusters that do not intersect.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#34;posts.txt&#34;</span>, encoding<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;utf-8&#34;</span>) <span style="color:#66d9ef">as</span> inp:
</span></span><span style="display:flex;"><span>    posts <span style="color:#f92672">=</span> inp<span style="color:#f92672">.</span>readlines()
</span></span><span style="display:flex;"><span>vectorizer <span style="color:#f92672">=</span> TfidfVectorizer(use_idf<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>posts_coordinates <span style="color:#f92672">=</span> vectorizer<span style="color:#f92672">.</span>fit_transform(posts)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Number of clusters / Silhouette score&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> clusters_amount <span style="color:#f92672">in</span> range(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">21</span>, step):
</span></span><span style="display:flex;"><span>    model <span style="color:#f92672">=</span> KMeans(
</span></span><span style="display:flex;"><span>        n_clusters<span style="color:#f92672">=</span>clusters_amount,
</span></span><span style="display:flex;"><span>        init<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;k-means++&#39;</span>,
</span></span><span style="display:flex;"><span>        max_iter<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>,
</span></span><span style="display:flex;"><span>        n_init<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>,
</span></span><span style="display:flex;"><span>        verbose<span style="color:#f92672">=</span><span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    categories <span style="color:#f92672">=</span> model<span style="color:#f92672">.</span>fit_predict(posts_coordinates)
</span></span><span style="display:flex;"><span>    silhouette_avg <span style="color:#f92672">=</span> silhouette_score(posts_coordinates, categories)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">%s</span><span style="color:#e6db74">: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74">&#34;</span> <span style="color:#f92672">%</span> (clusters_amount, silhouette_avg))
</span></span></code></pre></div><p>This script gives us the following data:</p>
<pre tabindex="0"><code>Categories Silhouette score
2          0,13
3          0,23
4          0,29
5          0,35
6          0,41
7          0,48
8          0,51
9          0,50
10         0,48
11         0,47
12         0,45
13         0,43
14         0,41
15         0,39
16         0,39
17         0,37
18         0,39
19         0,34
20         0,34
</code></pre><p><img loading="lazy" src="/images/2_number-of-categories-for-k-means/silhouette.png" alt="Silhouette chart"  />
</p>
<p>The highest score is achieved in <strong>8</strong> categories, the same number as the one we got using the elbow method.</p>
<h2 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h2>
<p>Choosing the correct and optimal number of categories is a very frequent problem in unsupervised machine learning and data clustering. Sometimes you can make a fairly good assumption by just looking at your data and studying its domain. But if you want to adjust this number to be more precise or find order in chaotic data it&rsquo;s good to test different metrics and see what insights about your data they provide. In this post, I have tried only two methods for one problem, but there are many more. Don&rsquo;t be afraid to try something new!</p>
<h2 id="links">Links<a hidden class="anchor" aria-hidden="true" href="#links">#</a></h2>
<p>Scripts and dataset from this post: <a href="https://github.com/smyachenkov/clustering_categories_number_demo">https://github.com/smyachenkov/clustering_categories_number_demo</a></p>
<p>Elbow method description: <a href="https://wikipedia.org/wiki/Elbow_method_(clustering)">https://wikipedia.org/wiki/Elbow_method_(clustering)</a></p>
<p>Silhouette method description: <a href="https://wikipedia.org/wiki/Silhouette_(clustering)">https://wikipedia.org/wiki/Silhouette_(clustering)</a>)</p>
<p>Problem of choosing number of clusters in a dataset: <a href="https://wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">https://wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set</a></p>
<p>K-Means implementation in scikit-learn library: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p>
<p>Silhouette metric implementation in scikit-learn library: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html</a></p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://smyachenkov.com/tags/machine-learning/">machine learning</a></li>
      <li><a href="https://smyachenkov.com/tags/categorization/">categorization</a></li>
      <li><a href="https://smyachenkov.com/tags/k-means/">k-means</a></li>
    </ul>


<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on twitter"
        href="https://twitter.com/intent/tweet/?text=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods&amp;url=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f&amp;hashtags=machinelearning%2ccategorization%2ck-means">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f&amp;title=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods&amp;summary=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods&amp;source=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on reddit"
        href="https://reddit.com/submit?url=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f&title=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on facebook"
        href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on whatsapp"
        href="https://api.whatsapp.com/send?text=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods%20-%20https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share Number of Categories for K-Means: Elbow and Silhouette Methods on telegram"
        href="https://telegram.me/share/url?text=Number%20of%20Categories%20for%20K-Means%3a%20Elbow%20and%20Silhouette%20Methods&amp;url=https%3a%2f%2fsmyachenkov.com%2fnumber-of-categories-for-k-means%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2023 <a href="https://smyachenkov.com/">Stanislav Myachenkov</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
