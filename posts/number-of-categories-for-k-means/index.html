<!doctype html>

<html lang="en">

<head>
  <title>Number of Categories for K-Means: Elbow and Silhouette Methods - Stanislav Myachenkov</title>
  <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta name="description" content="The HTML5 Herald" />
<meta name="author" content="Stanislav Myachenkov" /><meta property="og:title" content="Number of Categories for K-Means: Elbow and Silhouette Methods" />
<meta property="og:description" content="K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://smyachenkov.com/posts/number-of-categories-for-k-means/" />
<meta property="article:published_time" content="2019-05-26T00:00:00+03:00" />
<meta property="article:modified_time" content="2019-05-26T00:00:00+03:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Number of Categories for K-Means: Elbow and Silhouette Methods"/>
<meta name="twitter:description" content="K-Means is a very common and powerful clusterization algorithm widely used in an unsupervised machine learning tasks for dividing data into categories. The only decision you have to make is the number of clusters you want your data to be divided into — k number."/>

<meta name="generator" content="Hugo 0.78.2" />
    

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.1/normalize.min.css" integrity="sha256-l85OmPOjvil/SOvVt3HnSSjzF1TUMyT9eV0c2BzEGzU=" crossorigin="anonymous" />
  <link rel="stylesheet" href="https://smyachenkov.com/fontawesome/css/all.min.css" />
  
    <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto+Slab|Ruda" />
  
  
  <link rel="stylesheet" type="text/css" href="/css/styles.css" /><link rel='stylesheet' href='https://smyachenkov.com/css/links.css'></head>

<body>
  <div id="container">
    <header>
      <h1>
                <a href="/">Stanislav Myachenkov</a>
            </h1>

      <ul id="social-media">
             <li>
               <a href="mailto:mailto:s.myachenkov@gmail.com" title="Email me">
               <i class="fas fa-envelope fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://github.com/smyachenkov" title="GitHub">
               <i class="fab fa-github fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://linkedin.com/in/stanislav-myachenkov" title="LinkedIn">
               <i class="fab fa-linkedin fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://www.instagram.com/s.myachenkov" title="Instagram">
               <i class="fab fa-instagram fa-lg"></i>
               </a>
             </li>
             <li>
               <a href="https://telegram.me/smyachenkov" title="Telegram">
               <i class="fab fa-telegram fa-lg"></i>
               </a>
             </li>
      </ul>
      
      <p><em>Notes about programming and dev culture.</em></p>
      
    </header>

    
<nav>
    <ul>
        
        <li>
            <a class="" href="/">
                <i class="fa-li fa  fa-lg"></i><span>Posts</span>
            </a>
        </li>
        
        <li>
            <a class="" href="/tags">
                <i class="fa-li fa  fa-lg"></i><span>Tags</span>
            </a>
        </li>
        
        <li>
            <a class="" href="/about">
                <i class="fa-li fa  fa-lg"></i><span>About</span>
            </a>
        </li>
        
    </ul>
</nav>


    <main>




<article>

    <h1>Number of Categories for K-Means: Elbow and Silhouette Methods</h1>

    
      <aside>
    <ul>
        <li>
            <time class="post-date" datetime="2019-05-26T00:00:00&#43;03:00">May 26, 2019</time>
        </li>
        
        

        
        <li>
            <em>
                
                    
                    <a href="/tags/machine-learning">#machine learning</a>
                
                    , 
                    <a href="/tags/categorization">#categorization</a>
                
                    , 
                    <a href="/tags/k-means">#k-means</a>
                
            </em>
        </li>
        

        <li>5 minute read</li>
    </ul>
</aside>

    

    


    <p><a href="https://wikipedia.org/wiki/K-means_clustering"><strong>K-Means</strong></a> is a very common and powerful clusterization algorithm widely used in an <a href="https://wikipedia.org/wiki/Unsupervised_learning">unsupervised machine learning</a> tasks for dividing data into categories.
The only decision you have to make is the number of clusters you want your data to be divided into — <em>k</em> number.</p>
<p>Sometimes you already know how many categories you need to have. It depends a lot on the type of your problem, your data, and the problems you are solving. For example, if you want to divide the dataset of people&rsquo;s measurements into t-shirt sizes, you already know that t-shirts are measured from XXS to XXL and you can say with confidence that you know how many categories your data will have.</p>
<p>But often we face another type of a problem — when you don&rsquo;t know the number of categories and you want to find it. One example of this problem is categorization of social media hashtags. <a href="http://smyachenkov.com/posts/categorizing-instagram-tags-with-k-means/">In my previous post</a>, you can read more about it.</p>
<p>There are a lot of methods of finding optimal number of categories in a dataset, and I will focus on the 2 most popular for the K-Means algorithm: the <a href="https://wikipedia.org/wiki/Elbow_method_(clustering)">Elbow</a> and the <a href="https://wikipedia.org/wiki/Silhouette_(clustering)">Silhouette</a> methods.</p>
<h2 id="dataset">Dataset</h2>
<p>I will test both methods on a small synthetic <a href="https://raw.githubusercontent.com/smyachenkov/clustering_categories_number_demo/master/posts.txt">dataset</a> of Instagram posts with 50 entries. It contains 50 entries with 8 groups of 5 posts from different categories plus 2 groups of 5 posts from mixed categories.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">{camping, mothernature, hike, earth, rain, wildlife, landscapestyles, naturewalk, natureonly}
...
{streetview, streetphotographers, streetclassics, street_photo_club, streetphotographers}
...
{architecture, archilovers, architecture_hunter, architecturelovers, creative_architecture}
...
{ireland, dublin, guinness, instaireland, discoverireland}
...
{ocean, sand, ocean, water, waves, seaside, wave}
...
{portrait_shots, portrait_mood, portraitsociety, portraitvision, portraitoftheday, portraitmode}
...
{ireland, dublin, guinness, instaireland, discoverireland, camping, mothernature, hike, earth, rain}
...
{catsofinstagram, cat, cats, cats_of_instagram, catoftheday, petstagram, catsagram}
...
{minimal_perfection, minimalmood, minimalistic, minimalismo, minimal, minimalism_world}
...
{architecture, archilovers, creative_architecture, minimalmood, minimalistic, minimal}
</code></pre></div><p>Lets try it!</p>
<h2 id="elbow-method">Elbow method</h2>
<p>The general idea for both methods is to try different values for <em>k</em> number and measure some of its metrics. In the elbow method, it&rsquo;s the sum of the squared distances of an object to the closest centroid.</p>
<p>Let&rsquo;s measure how different the performance params will be for the number of categories from 1 to 20.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#ff79c6">with</span> <span style="color:#8be9fd;font-style:italic">open</span>(<span style="color:#f1fa8c">&#34;posts.txt&#34;</span>, encoding<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;utf-8&#34;</span>) <span style="color:#ff79c6">as</span> inp:
    posts <span style="color:#ff79c6">=</span> inp<span style="color:#ff79c6">.</span>readlines()
vectorizer <span style="color:#ff79c6">=</span> TfidfVectorizer(use_idf<span style="color:#ff79c6">=</span>True)
posts_coordinates <span style="color:#ff79c6">=</span> vectorizer<span style="color:#ff79c6">.</span>fit_transform(posts)
<span style="color:#ff79c6">print</span>(<span style="color:#f1fa8c">&#34;Number of clusters / Inertia / Diff&#34;</span>)
previous <span style="color:#ff79c6">=</span> <span style="color:#bd93f9">0</span>
<span style="color:#ff79c6">for</span> clusters_amount <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(<span style="color:#bd93f9">1</span>, <span style="color:#bd93f9">21</span>, step):
    model <span style="color:#ff79c6">=</span> KMeans(
        n_clusters<span style="color:#ff79c6">=</span>clusters_amount,
        init<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;k-means++&#39;</span>,
        max_iter<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>,
        n_init<span style="color:#ff79c6">=</span><span style="color:#bd93f9">5</span>,
        verbose<span style="color:#ff79c6">=</span>False
    )
    model<span style="color:#ff79c6">.</span>fit_predict(posts_coordinates)
    inertia <span style="color:#ff79c6">=</span> model<span style="color:#ff79c6">.</span>inertia_
    diff <span style="color:#ff79c6">=</span> previous <span style="color:#ff79c6">-</span> inertia
    previous <span style="color:#ff79c6">=</span> inertia
    <span style="color:#ff79c6">print</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">%s</span><span style="color:#f1fa8c">: </span><span style="color:#f1fa8c">%s</span><span style="color:#f1fa8c"> </span><span style="color:#f1fa8c">%s</span><span style="color:#f1fa8c">&#34;</span> <span style="color:#ff79c6">%</span> (clusters_amount, inertia, <span style="color:#f1fa8c">&#34;-&#34;</span> <span style="color:#ff79c6">if</span> clusters_amount <span style="color:#ff79c6">==</span> <span style="color:#bd93f9">1</span> <span style="color:#ff79c6">else</span> diff))
</code></pre></div><p>This script gives us the following data where <strong>Categories</strong> column is the number of categories, <strong>Inertia</strong> is the sum of squared distances to the closest centroid, and <strong>Diff</strong> is the difference between current and previous values of Inertia:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">Categories  Inertia Diff
1           43,56   -
2           37,13   6,43
3           31,82   5,30
4           26,74   5,08
5           21,82   4,92
6           17,93   3,88
7           12,74   5,19
8           9,07    3,66
9           7,74    1,33
10          6,57    1,16
11          5,99    0,57
12          5,76    0,23
13          5,54    0,21
14          5,31    0,22
15          5,10    0,21
16          4,86    0,23
17          4,64    0,22
18          4,56    0,08
19          4,25    0,30
20          4,05    0,20
</code></pre></div><p><img src="/images/2_number-of-categories-for-k-means/elbow_chart.png" alt="Elbow chart">
<img src="/images/2_number-of-categories-for-k-means/elbow_diff_chart.png" alt="Elbow diff chart"></p>
<p>Here we can see that the Inertia parameter almost stops decreasing after the number of categories reaches <strong>8</strong>. It&rsquo;s even more clear on the second diagram, where the largest drop in speed has been achieved after the <strong>8</strong>th category and every difference after that does not change much.</p>
<p>Now let&rsquo;s try to confirm this number with a silhouette method.</p>
<h2 id="silhouette-method">Silhouette method</h2>
<p>Silhouette metric has its values in a range from -1 to 1 and measures how far or close are points in clusters to points of another cluster. The higher the value — the farther points of clusters are from each other. And that&rsquo;s what we want to achieve — more distinct clusters that do not intersect.</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#ff79c6">with</span> <span style="color:#8be9fd;font-style:italic">open</span>(<span style="color:#f1fa8c">&#34;posts.txt&#34;</span>, encoding<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#34;utf-8&#34;</span>) <span style="color:#ff79c6">as</span> inp:
    posts <span style="color:#ff79c6">=</span> inp<span style="color:#ff79c6">.</span>readlines()
vectorizer <span style="color:#ff79c6">=</span> TfidfVectorizer(use_idf<span style="color:#ff79c6">=</span>True)
posts_coordinates <span style="color:#ff79c6">=</span> vectorizer<span style="color:#ff79c6">.</span>fit_transform(posts)
<span style="color:#ff79c6">print</span>(<span style="color:#f1fa8c">&#34;Number of clusters / Silhouette score&#34;</span>)
<span style="color:#ff79c6">for</span> clusters_amount <span style="color:#ff79c6">in</span> <span style="color:#8be9fd;font-style:italic">range</span>(<span style="color:#bd93f9">2</span>, <span style="color:#bd93f9">21</span>, step):
    model <span style="color:#ff79c6">=</span> KMeans(
        n_clusters<span style="color:#ff79c6">=</span>clusters_amount,
        init<span style="color:#ff79c6">=</span><span style="color:#f1fa8c">&#39;k-means++&#39;</span>,
        max_iter<span style="color:#ff79c6">=</span><span style="color:#bd93f9">10</span>,
        n_init<span style="color:#ff79c6">=</span><span style="color:#bd93f9">5</span>,
        verbose<span style="color:#ff79c6">=</span>False
    )
    categories <span style="color:#ff79c6">=</span> model<span style="color:#ff79c6">.</span>fit_predict(posts_coordinates)
    silhouette_avg <span style="color:#ff79c6">=</span> silhouette_score(posts_coordinates, categories)
    <span style="color:#ff79c6">print</span>(<span style="color:#f1fa8c">&#34;</span><span style="color:#f1fa8c">%s</span><span style="color:#f1fa8c">: </span><span style="color:#f1fa8c">%s</span><span style="color:#f1fa8c">&#34;</span> <span style="color:#ff79c6">%</span> (clusters_amount, silhouette_avg))
</code></pre></div><p>This script gives us the following data:</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#282a36;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-fallback" data-lang="fallback">Categories Silhouette score
2          0,13
3          0,23
4          0,29
5          0,35
6          0,41
7          0,48
8          0,51
9          0,50
10         0,48
11         0,47
12         0,45
13         0,43
14         0,41
15         0,39
16         0,39
17         0,37
18         0,39
19         0,34
20         0,34
</code></pre></div><p><img src="/images/2_number-of-categories-for-k-means/silhouette.png" alt="Silhouette chart"></p>
<p>The highest score is achieved in <strong>8</strong> categories, the same number as the one we got using the elbow method.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Choosing the correct and optimal number of categories is a very frequent problem in unsupervised machine learning and data clustering. Sometimes you can make a fairly good assumption by just looking at your data and studying its domain. But if you want to adjust this number to be more precise or find order in chaotic data it&rsquo;s good to test different metrics and see what insights about your data they provide. In this post, I have tried only two methods for one problem, but there are many more. Don&rsquo;t be afraid to try something new!</p>
<h2 id="links">Links</h2>
<p>Scripts and dataset from this post: <a href="https://github.com/smyachenkov/clustering_categories_number_demo">https://github.com/smyachenkov/clustering_categories_number_demo</a></p>
<p>Elbow method description: <a href="https://wikipedia.org/wiki/Elbow_method_(clustering)">https://wikipedia.org/wiki/Elbow_method_(clustering)</a></p>
<p>Silhouette method description: <a href="https://wikipedia.org/wiki/Silhouette_(clustering)">https://wikipedia.org/wiki/Silhouette_(clustering)</a>)</p>
<p>Problem of choosing number of clusters in a dataset: <a href="https://wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set">https://wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set</a></p>
<p>K-Means implementation in scikit-learn library: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html</a></p>
<p>Silhouette metric implementation in scikit-learn library: <a href="https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html">https://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html</a></p>


</article>


<section class="post-nav">
    <ul>
        
        <li>
            <a href="https://smyachenkov.com/posts/categorizing-instagram-tags-with-k-means/"><i class="fa fa-chevron-circle-left"></i> Categorizing Instagram Tags with K-Means</a>
        </li>
        
        
        <li>
            <a href="https://smyachenkov.com/posts/kotlin-static-analysis-tools/">Kotlin Static Analysis Tools <i class="fa fa-chevron-circle-right"></i> </a>
        </li>
        
    </ul>
</section>
  
    
    
        <section class="comments-block">
      <button id="show-comments" style="display: none;"><i class="fa fa-comments"></i> Add/View Comments</button>
</section>

<section id="disqus_thread"></section>

<script>
      (function () {
            
            
            if (window.location.hostname == "localhost")
                  return;

            var disqus_loaded = false;
            var disqus_shortname = 'smyachenkov';
            var disqus_button = document.getElementById("show-comments");

            var disqus_autoload =  null ;
            var disable_comment =  null ;

            if (disable_comment)
                  return;

            disqus_button.style.display = "";

            if (disqus_autoload){
                  disqus();
            }else{
                  disqus_button.addEventListener("click", disqus, false);
            }

            function disqus() {

                  if (!disqus_loaded) {
                        disqus_loaded = true;

                        var e = document.createElement("script");
                        e.type = "text/javascript";
                        e.async = true;
                        e.src = "//" + disqus_shortname + ".disqus.com/embed.js";
                        (document.getElementsByTagName("head")[0] ||
                              document.getElementsByTagName("body")[0])
                        .appendChild(e);

                        
                        document.getElementById("show-comments").style.display = "none";
                  }
            }

            
            var hash = window.location.hash.substr(1);
            if (hash.length > 8) {
                  if (hash.substring(0, 8) == "comment-") {
                        disqus();
                  }
            }

            
            if (/bot|google|baidu|bing|msn|duckduckgo|slurp|yandex/i.test(navigator.userAgent)) {
                  disqus();
            }
      })();
</script>

    
  





</main>
    <footer>
        <h6> |
            Rendered by <a href="https://gohugo.io" title="Hugo">Hugo</a> |
            <a href="https://smyachenkov.com/index.xml">Subscribe </a></h6>
    </footer>
</div>
<script src="/js/scripts.js"></script>

  
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-136218929-1', 'auto');
	
	ga('send', 'pageview');
}
</script>



</body>

</html>

